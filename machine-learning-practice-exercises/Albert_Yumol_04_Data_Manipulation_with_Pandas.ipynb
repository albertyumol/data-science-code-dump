{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"sections\"></a></p>\n",
    "\n",
    "\n",
    "# Sections\n",
    "\n",
    "- <a href=\"#DS\">Data Structure</a><br>\n",
    "- <a href=\"#DM\">Data Manipulation</a><br>\n",
    "- <a href=\"#grouping\">Grouping and aggregration</a><br>\n",
    "- <a href=\"#miss\">Handling Missing Data</a><br>\n",
    "- <a href=\"#sol\">Solutions</a><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "<p><a name=\"DS\"></a></p>\n",
    "### Data Structure\n",
    "\n",
    "- Pandas is a Python package built on top of NumPy.  It is useful for special array handling, data manipulation, plotting, and web scraping.  \n",
    "\n",
    "- There are four new data structure objects in Pandas: Series, DataFrame, Time Series and Panel. The first two will be discussed.\n",
    "\n",
    "- The *DataFrame* object borrows its name from the R object.\n",
    "\n",
    "- Pandas is particularly strong in the area of handling spreadsheet structures, dealing with missing data, and processing time series data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the new data types introduced by pandas:\n",
    "\n",
    "- **Series**: 1D labeled homogeneously-typed array.\n",
    "- **DataFrame**: General 2D labeled, size-mutable tabular structure with potentially heterogeneously-typed columns.\n",
    "- **Time Series**: Series with index containing datetimes.\n",
    "- **Panel**: General 3D labeled, also size-mutable array.\n",
    "\n",
    "Import the package, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"series\"></a></p>\n",
    "## Series\n",
    "\n",
    "- A series is a one-dimensional array-like object containing homogenously typed elements.   \n",
    "- Each element has an associated data label, called its index. By default, the index consists of ordinary array indices, i.e. consecutive integers starting from zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = pd.Series(['a', 'b', 'c', 'd'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.index  #this is the default index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An entry can be retrieved using the index, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Often it will be more desirable to create a series with a custom index. \n",
    "- Here the index is manually set the index from 1 to 4, with 4 repeated. Note there are two rows with the same index 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    a\n",
       "2    b\n",
       "3    c\n",
       "4    d\n",
       "4    e\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2 = pd.Series(['a', 'b', 'c', 'd','e'], index=[1, 2, 3, 4, 4])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calling that entry gives both values.  In this way a series is different from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([1, 2, 3, 4, 4], dtype='int64')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.index #custom index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    d\n",
       "4    e\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The index value may also be a string.  A new entry with a string index is written:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1              a\n",
       "2              b\n",
       "3              c\n",
       "4              d\n",
       "4              e\n",
       "something    660\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2['something']=660\n",
    "obj2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the entries are not retrievable by their place but the value of their index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0de45ba6934b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This one also works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4721\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4722\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4723\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4724\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4725\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 5"
     ]
    }
   ],
   "source": [
    "print(obj[1])\n",
    "print(obj2[5]) # This one also works\n",
    "print(obj2[6]) # KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The attribute `values` returns all the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a', 'b', 'c', 'd', 'e', 660], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.values[1]   # obj.values is simply an array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **Series** object is similar to a **dictionary**, `Series.index` is like `dictionary.keys`, and `Series.values` is like `dictionary.values`. Directly convert a dictionary to a Series, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    a\n",
       "2    b\n",
       "3    c\n",
       "4    d\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ = {1: 'a', 2: 'b', 3: 'c', 4: 'd'}\n",
    "obj3 = pd.Series(dict_)\n",
    "obj3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert a Series back to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'b', 3: 'c', 4: 'd'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj3.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ntoe what happens in translating a series with repeated index values.  Only the last entry for the repeated index is included in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a', 2: 'b', 3: 'c', 4: 'e', 'something': 660}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj2.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"DF\"></a></p>\n",
    "## DataFrame\n",
    "\n",
    "- A data frame represents a tabular, spreadsheet-like data structure containing an ordered collection of columns.\n",
    "- Each column can be a different type (integers, strings, floating point numbers, Python objects, etc.).  \n",
    "- All columns must be the same length, to give the data frame a defined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>year</th>\n",
       "      <th>production_Moz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gold</td>\n",
       "      <td>2013</td>\n",
       "      <td>107.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gold</td>\n",
       "      <td>2014</td>\n",
       "      <td>109.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Silver</td>\n",
       "      <td>2014</td>\n",
       "      <td>868.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silver</td>\n",
       "      <td>2015</td>\n",
       "      <td>886.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  commodity  year  production_Moz\n",
       "0      Gold  2013           107.6\n",
       "1      Gold  2014           109.7\n",
       "2    Silver  2014           868.3\n",
       "3    Silver  2015           886.7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'commodity': ['Gold', 'Gold', 'Silver', 'Silver'],\n",
    "        'year': [2013, 2014, 2014, 2015],\n",
    "        'production_Moz': [107.6, 109.7, 868.3, 886.7]} #world wide in million oz\n",
    "\n",
    "# convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['commodity', 'year', 'production_Moz'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index #standard index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commodity</th>\n",
       "      <th>year</th>\n",
       "      <th>production_Moz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gold</td>\n",
       "      <td>2013</td>\n",
       "      <td>107.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gold</td>\n",
       "      <td>2014</td>\n",
       "      <td>109.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Silver</td>\n",
       "      <td>2014</td>\n",
       "      <td>868.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Silver</td>\n",
       "      <td>2015</td>\n",
       "      <td>886.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  commodity  year  production_Moz\n",
       "4      Gold  2013           107.6\n",
       "5      Gold  2014           109.7\n",
       "6    Silver  2014           868.3\n",
       "7    Silver  2015           886.7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index=([4,5,6,7])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index #custom integer index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The index may be set using the method `set_index`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df.set_index('commodity')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.index #custom string index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#floats can also be an index\n",
    "df.set_index('production_Moz').index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['year'] #this yields a pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['year']] #this yields a pandas data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataframe can restore the original index using the mathod `reset_index`, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A data frame can also be created with a nested list. The two ways are equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2=pd.DataFrame([[107.6, 'Gold', 2013],\n",
    "                   [109.7, 'Gold', 2014],\n",
    "                   [868.3, 'Silver', 2014],\n",
    "                   [886.7, 'Silver', 2015]], \n",
    "                    columns=['production_Moz','commodity','year'])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A data frame has an attribute **values**, which is of the multidimensional array type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.values)\n",
    "print('-'*55)\n",
    "print(df_2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data frame v.s. series is similar to 2D array v.s. 1D array. A data frame has column names for the added dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df.columns)  # column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each column in a DataFrame can be retrieved as a Series. \n",
    "- There are two ways to get the column: to retrieve by attribute and to retrieve by dictionary-like notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.year         # retrieve by attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['year']  # retrieve by dictionary-like notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The name of an individual column may be changed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns=['commodity', 'com','production']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace('com','metal')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Indexing a pandas data frame is similar to indexing a numpy array. In pandas the first index retrieves a column and the second index retrieves the row.  \n",
    "- To return the third element of the metal column, use the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['metal'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Slicing a pandas data frame is also similar to slicing a numpy array.  The following code returns the second and third elements of the production column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['production'][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to slice multiple columns pass a list of column names.  The following represents the world production of gold and silver in 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['metal','production']][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 1** \n",
    "\n",
    "Create a Pandas DataFrame, named 'NYC', whose columns are 'boro', 'pop' and 'area'. The frame represents the five boroughs of New York City, including the 2010 census population (in millions),and land area in square miles.  The rows represent the following:\n",
    "\n",
    "- The Bronx is 42 square miles.  In the 2010 census, the Bronx had 1.39 million people.\n",
    "- Manhattan, with 2010 population 1.59 million, has an area of 23 square miles.\n",
    "- Brooklyn is 71 square miles.  The 2010 population was 2.47 million.\n",
    "- In 2010, Staten Island had 0.44 million inhabitants.  It is 59 square miles.\n",
    "- 2.23 million people lived across the 109 square miles of Queens, in 2010.\n",
    "\n",
    "Create a new column representing the population density using:\n",
    "```\n",
    "NYC['density']=NYC['pop']/NYC['area']\n",
    "```\n",
    "\n",
    "Now set the index of NYC to be the borough names using `set_index` function of a data frame. Make sure to update the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"IO\"></a></p>\n",
    "## I/O tools\n",
    "\n",
    "- Pandas has a number of functions for reading tabular data as a data frame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat foo.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!type foo.csv # Windows user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('foo.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In some cases, there is no header in the file. By setting `header = None`, the column names will be filled with incremental numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat foo_noheader.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_df=pd.read_csv('foo_noheader.csv', header = None)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The column names may then be set, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_df.columns=['a', 'b', 'c', 'd', 'message']\n",
    "my_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another way is to pass the column names (as a list of strings) to the `names` parameter in `read_csv`.  \n",
    "- Note the parameter is called \"names\" instead of \"columns\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the names manually\n",
    "pd.read_csv('foo_noheader.csv', \n",
    "             names=['a', 'b', 'c', 'd', 'message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing files has been covered. This exercise demonstrates file exporting.\n",
    "\n",
    "**Exercise 2** \n",
    "\n",
    "- Write the data frame, `NYC`, to a file, NYC.csv. The function `to_csv` is useful for this task.\n",
    "- Now load 'NYC.csv' to a data frame named NYC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n",
    "NYC.to_csv('NYC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat NYC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NYC2=pd.read_csv('NYC.csv', index_col=0) # use the first column as index\n",
    "NYC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"DM\"></a></p>\n",
    "# Data Manipulation in Pandas\n",
    "\n",
    "- Like numpy, pandas defines many broadcast operations, as well as numerous methods of manipulating data.\n",
    "\n",
    "<p><a name=\"concat\"></a></p>\n",
    "### concat\n",
    "Pandas DataFrames can be expanded in both directions. First create two data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9).reshape((3, 3)), \n",
    "                   columns=['a', 'b', 'c'],\n",
    "                   index=['one', 'two', 'three'])\n",
    "df2 = pd.DataFrame(np.arange(6).reshape((3, 2)), \n",
    "                   columns=['d','e'],\n",
    "                   index=['three', 'two','one'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the two data frames have the same number of rows, it is natural to combine them \"horizontally\".  \n",
    "- Note the concatenation takes place on the name of the index and not the order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The argument \"axis = 1\" means expanding along the column indices. Setting \"axis = 0\" will combine two data frames with same number of columns vertically. \n",
    "\n",
    "- Now changing the name of row 'one' to One' gives it a different index.  In this case the concatenation will use all the rows, filling in missing values with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.arange(9).reshape((3, 3)), \n",
    "                   columns=['a', 'b', 'c'],\n",
    "                   index=['One', 'two', 'three'])\n",
    "df2 = pd.DataFrame(np.arange(6).reshape((3, 2)), \n",
    "                   columns=['d','e'],\n",
    "                   index=['three', 'two','one'])\n",
    "print(df1,'\\n\\n',df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To include only the shared rows, set the join parameter to 'inner', as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis = 1, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**\n",
    "\n",
    "In the iPython notebook, create the data frame below.  Observe that this is a data frame with new features.  \n",
    "\n",
    "There are three new features:\n",
    "\n",
    "- **high_point** is the location of highest elevation \n",
    "- **geography** indicates if the borough is an island, on an island, or mainland\n",
    "- **inception** indicates the year of incorporation into the City of New York\n",
    "\n",
    "Combine 'new_features' with the old NYC data frame to make a new data frame named 'NYC3'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features = pd.DataFrame({'high_point': ['Battle Hill', 'Chapel Farm', 'North Glen Oaks', 'Bennett Park','Todt Hill'],\\\n",
    "                            'geography':['on island','on mainland','on island','is an island','is an island'],\\\n",
    "                           'inception':['1634','1898','1683','1624','1683']},\\\n",
    "                            index=['Brooklyn', 'Bronx', 'Queens', 'Manhattan',\"Staten Island\"])\n",
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"sort\"></a></p>\n",
    "### sort\n",
    "- It is possible to order the rows of data frames using `sort_values()`.  This object method takes a column name as an argument.\n",
    "- It is used on the new_features data frame to order by date of inception, as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features.sort_values('inception')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the sort is done in ascending order.  To apply the sort in decending order, set the `ascending` parameter to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features.sort_values('inception',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"merge\"></a></p>\n",
    "### merge\n",
    "Merging is the most common way to combine multiple data frames. Create two data frames first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame([['a','b','c'],['d','e','f'],['g','h','i']]\\\n",
    "                   ,columns=['col1','col2','col3'])\n",
    "df4 = pd.DataFrame({'col2':['x','e','b','z'],'col4':[1,2,3,4],'col5':['i','f','e','h']})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merging will use the **`on`** column as a key for the merge.  The code below identifies the column ‘col2’ from both data frames. \n",
    "- The argument **`how`** set to 'inner' makes the merge only keep rows occuring in both data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, how='inner', on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The default value of the parameter `how` is 'inner'. The following code performs the same task as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To keep every row in df1 then set the parameter `how` = 'left'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, how='left', on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To keep all rows from both df1 and df2, set the parameter `how` = 'outer'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, how='outer', on ='col2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the `on` column does not have the same name in the two data frames, use 'left_on' and 'right_on' to indicate how to perform the merge.  \n",
    "- Note that columns with the same name, in the two data frames, will be named with an x or y character appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.merge(df3, df4, left_on='col2', right_on='col5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**\n",
    "\n",
    "- Run the following code to create a data frame, 'Elevations'. It contains NYC locations and their elevation in feet.  How is this related to the NYC data frame? Why separate this information into another data frame?\n",
    "- Combine this data with the full NYC3 data frame to make a new data frame named NYC4.\n",
    "- Note NYC3 is indexed using boro, we want to keep it after the merge.\n",
    "- Change the name of the elevation column to 'peak_elevation'.\n",
    "- Order the data frame by highest to lowest 'peak_elevation'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Elevations = pd.DataFrame([['Battle Hill',220],['Marcus Garvey Park',103],['Bennett Park',265],\\\n",
    "                           ['Todt Hill',410],['Washington Square Park',27],['Chapel Farm',280],\\\n",
    "                           ['Bryant Park',58],['North Glen Oaks',258],['St Marys Park',47]],\n",
    "                      columns=['location', 'elevation'])\n",
    "Elevations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"SF\"></a></p>\n",
    "### selection and filter\n",
    "\n",
    "- The `loc` method provides purely label (index/columns)-based indexing. \n",
    "- This method allows selection from a data frame by index and columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following returns a single column of df1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['a'] #gives series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[1] #this throws an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(df1['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[['a']] #gives a single column data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1[['a','c']] #gives a multi column data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following uses `loc` to return a single row of df1, using the index string name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.loc['two'] # the row that has index two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.loc[['two']] # the row that has index two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A second parameter is passed to loc to specify the chosen column. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.loc['two', 'b'] # the row that has index two and column b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note the two ways to accomplish this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(df1.loc['two', 'b'])\n",
    "print(df1['b'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fancy indexing can be done with `loc` in pandas, as was done in Numpy. Select a row with a condition, as follows. \n",
    "- The code below returns all columns for the rows in which column 'a' is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.loc[df1.a==0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Columns are selected in a similar way.  The code below returns all rows for the columns in which row 'one' is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.loc[:, df1.loc['One']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note: loc only accepts labels as input. If you try to use numbers, it will give you an error. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.loc[1, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To select data by position number, use iloc. The iloc method provides a purely position based indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select as a matrix \n",
    "# row 2, col 3\n",
    "df1.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first row, first two columns\n",
    "# return a Series\n",
    "row1 = df1.iloc[0,:2]\n",
    "row1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also use a list to slice the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.iloc[[0,2], :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NYC4 #look at NYC4 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the i=2 and i=4 column of NYC4\n",
    "NYC4.iloc[:,[2,4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DataFrame’s apply method applies a function on 1D arrays to each column or row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: max(x), axis=0) # 0 stands for apply to each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.apply(lambda x: min(x), axis=1) # 1 stands for apply to each row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you just want to apply the function a single column, you can extract that specific series first and then call the `map()` method just like the `map` operator in Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.a.map(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this removes row 'two'\n",
    "df1.loc[df1.index != 'two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this removes column 'a'\n",
    "df1.drop('a', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rows and columns may also be removed using fancy indexing or `drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this removes column b\n",
    "df1.loc[:,df1.columns != 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember the following expression is a boolean and acts as a mask\n",
    "df1.columns != 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this removes column 'b'\n",
    "df1.drop('b', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p><a name=\"miss\"></a></p>\n",
    "# Handling Missing Data\n",
    "\n",
    "- Missing or, equivalently, corrupt data is an unavoidable reality in processing large data sets.  There are various ways of dealing with it, depending upon the circumstances:\n",
    " - Discard it, and all related data.\n",
    " - Interpolate values from surrounding data\n",
    " - Isolate it and analyze it separately\n",
    "\n",
    "- Which approach to use is a scientific question.  Whatever approach is chosen, pandas has computational methods to carry it out.\n",
    "- Read a csv file that contains NaNs. **Note:** index_col is set to 0.  This means the first column is used as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e8cfb5431f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_miss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'missing.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_miss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df_miss = pd.read_csv('missing.csv',index_col=0)\n",
    "df_miss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- To figure out where the missing data is, use the `isnull()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many missing values are there in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(df_miss.isnull()) # Built-in sum doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Summing up the boolean array reports how many missing values are in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(df_miss.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The same is possible for rows by setting the axis parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(df_miss.isnull(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To isolate the rows in which there are null values, aggregate the `df.isnull()` boolean data frame along rows, using `any` with `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask=df_miss.isnull().any(axis=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Passing the boolean Series to the first position of the `loc` method of the DataFrame selects the rows that have value equal to True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.loc[mask,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similarly, if you want to locate the rows that contains only missing values, you can use `all()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask=df_miss.isnull().all(axis=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Exercise 5**\n",
    "- Handling NaNs has been shown, however, not all missing values are NaNs. Consider the example below:\n",
    "\n",
    "```\n",
    "Employee = pd.read_csv('Employee_continue.csv')\n",
    "```\n",
    "\n",
    "Print the data frame, looking for missing values by inspection. How many missing values are there? Some of the missing values might not be NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Employee = pd.read_csv('Employee_continue.csv')\n",
    "Employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- See '?' in the data frame. For a small data frame like this the '?' may be replaced by `np.nan` manually. In dealing with a large data frame, it is more efficient to use the function `replace`. Use `replace` to swap '?' with `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many missing values are there in each row? How many in each column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print the columns with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the missing values are represented by `NaN`s, Pandas provides various methods for handling them:\n",
    "\n",
    "<p><a name=\"dropna\"></a></p>\n",
    "## dropna\n",
    "- One option is to discard the rows with missing values. Below the arguments `axis=0` and `how='any'` indicate dropping *rows* with a NaN in *any* position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another option is to drop rows full of NaNs. This can be done with `how='all'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.dropna(axis=0, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Applying `dropna()` to the above data frame may be done once more. Drop a column with the argument `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.dropna(axis=0, how='all').dropna(axis=1, how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"fillna\"></a></p>\n",
    "## fillna\n",
    "\n",
    "- An alternative to discarding information is to **impute** the data. \n",
    "- This can be done with the `fillna()` function with the value to be imputed as the argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Another common way to impute is by the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss['one'].fillna(df_miss['one'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"interpolate\"></a></p>\n",
    "## Interpolate\n",
    "\n",
    "- Interpolation is the insertion of new data between preeexisting fixed points. Linear interpolation uses a linear function to create new data point.  \n",
    "- In pandas this is accomplished using `interpolate()` with the `method` parameter set to linear, `method='linear'`.  \n",
    "- This will fill in missing data points with a linear interpolation between the data points bordering the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_miss.interpolate(method='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since `df.loc['b','one']` is a NaN between `df.loc['a','one']` and `df.loc['c','one']`, the value inserted is the mean of them.\n",
    "- Note how this technique treats NaN values at the bottom of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df_miss.loc['a', 'one'] + df_miss.loc['c', 'one'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"grouping\"></a></p>\n",
    "\n",
    "# Grouping and Aggregation\n",
    "\n",
    "Grouping and  aggregation are critical components of data analysis which involve:\n",
    "\n",
    "- **Splitting** data into groups based on some features.\n",
    "- **Applying** a function to each group independently.\n",
    "- **Combining** the result into data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "Grouping splits a data frame into categorical groups, according to a given variable, or set of variables.   Consider the following data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Country = pd.read_csv('countries.csv',delimiter=';')\n",
    "Country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#choose the desires columns\n",
    "Country=Country[['Country','Continent','Population','Area','Coastline',\n",
    "                'Currency','Birthrate','Deathrate','Life expectancy']]\n",
    "#change the column names to lowercase\n",
    "Country.columns = Country.columns.str.lower()\n",
    "#drop columns with missing values (Antarctica)\n",
    "Country=Country.dropna(axis=0, how='any')\n",
    "#limit to countries with populations over 20 million\n",
    "Country=Country[Country['population']>20e6]\n",
    "#add a boolean valued column that is true for countries with coastlines\n",
    "Country['coastal']=Country['coastline']!=0\n",
    "Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will calculate the mean population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Country['population'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will calculate the sum of all populations in Asia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Country[Country['continent']=='Asia']['population'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This will return the number of land-locked countries in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Country[Country['coastal']==False].country.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To group the countries by continent, do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group = Country.groupby('continent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `group` is assigned the value returned by the `groupby` function, whose type is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `DataFrameGroupBy` object is an `iterable`. Iterate over the object and print the contents, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for item in group:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each `item` we print is a two element `tuple`. The first element is the grouping.  \n",
    "- The second element is a data frame for that grouping. There is an alternative way of iterating through the groupby object, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, values in group:\n",
    "    print(key) #this indicates the grouping\n",
    "    print('-'*70)\n",
    "    print(values) #this is a dataframe for that \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is a great way to print and inspect a `DataFrameGroupBy` object. Above was an example of **splitting**.\n",
    "- The size function includes the number of elements in each grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The following will return a data frame with the mean values for every coulumn in every grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you just want the mean of one specific column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group.birthrate.mean()\n",
    "# group[['birthrate']].mean() # This returns a data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The data frame can be grouped by multiple keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group2 = Country.groupby(['continent', 'currency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key, values in group2:\n",
    "    print(key)\n",
    "    print('-'*70)\n",
    "    print(values)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply multiple functions to each group with the method `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group.agg(['count', 'sum', 'min', 'max', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To look at a single column of the aggregate analysis, use the column indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group.agg(['count', 'sum', 'min', 'max', 'mean', 'std'])['birthrate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The column std is missing a value above because Australia only has one row in the data frame.\n",
    "- Also note that `sum` is an inappropriate function to apply to birthrate where it would be applicable to population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different aggregating functions can be applied to different columns. This can be done with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colFun = {'country':['count'],\n",
    "          'population': ['sum','min', 'max','mean','std'], \n",
    "          'area': ['sum','min', 'max','mean'],\n",
    "          'coastline':['sum','min', 'max'],\n",
    "          'birthrate':['min', 'max','mean','std'],\n",
    "          'deathrate':['min', 'max','mean','std'],\n",
    "          'life expectancy':['min', 'max','mean','std']}\n",
    "analysis=group.agg(colFun)\n",
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Custom aggregation functions may also be applied. In the previous examples, aggregation functions are applied to each **column** in a data frame. \n",
    "- Keep this in mind when defining a custom function. For example, build a function that computes the mean after removing maxima (truncated mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trunc_mean(x):    # x has to be a 'vector' (1d array or pandas Series)\n",
    "    sec=x[x!=x.max()]\n",
    "    if sec.shape[0]!=0:\n",
    "        return np.mean(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Country[Country['country']!='Australia' ].groupby('continent').agg(trunc_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**\n",
    "\n",
    "Using the data frame Country:\n",
    "\n",
    "- Find the minimum and maximum of the 'life expectancy' for costal and landlocked countries.\n",
    "- How many coastal and landlocked countries are in each continent? Determine the mean deathrate for coastal and landlocked countries in each continent.\n",
    "- Create a new column measuring population density.  Determine the mean population density of all the countries.  Create a new column 'dense' that is True for countries with higher than average density and False for lower than average density.\n",
    "- For each category of 'dense' compute the mean birthrate and the difference between the maximal birthrate and the minimal birthrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"sol\"></a></p>\n",
    "# Soluitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NYC=pd.DataFrame([['Bronx',1.39,42],\n",
    "                ['Manhattan',1.59,23],\n",
    "                ['Brooklyn',2.47,71],\n",
    "                ['Staten Island',0.44,59],\n",
    "                ['Queens',2.23,109]],columns=['boro','pop','area'])\n",
    "\n",
    "NYC['density']=NYC['pop']/NYC['area']\n",
    "NYC=NYC.set_index('boro')\n",
    "NYC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NYC3=pd.concat([NYC, new_features], axis = 1)\n",
    "NYC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NYC4=pd.merge(NYC3.reset_index(),Elevations,left_on='high_point',right_on='location').set_index('index')\n",
    "NYC4.columns=NYC4.columns.str.replace('elevation','peak_elevation')\n",
    "NYC4=NYC4.sort_values('peak_elevation',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Employee=Employee.replace('?',np.nan)\n",
    "Employee\n",
    "np.sum(Employee.isnull(), axis=1)\n",
    "np.sum(Employee.isnull(), axis=0)\n",
    "Employee.loc[Employee.isnull().any(axis=1),:]\n",
    "Employee.loc[:,Employee.isnull().any(axis=0) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Country.groupby('coastal').agg({'life expectancy':['min','max']})\n",
    "Country.groupby(['continent','coastal']).agg({'deathrate':['count','mean']})\n",
    "Country['density']=Country['population']/Country['area']\n",
    "Country['dense']=Country['density']>Country['density'].mean()\n",
    "def diff_(x):\n",
    "    return max(x)-min(x)\n",
    "Country.groupby('dense').agg({'birthrate':['mean',diff_]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
